{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad9d5336-a95b-44d9-a7cf-91d45399c6d1",
   "metadata": {},
   "source": [
    "# AI DATA MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117786a1-c538-48fb-8591-539b61e767eb",
   "metadata": {},
   "source": [
    "- Introduction to Data Science and Modeling with Python\n",
    "- Importing, representing and visualizing data\n",
    "- Data cleaning and integration\n",
    "- Data transformations and variable scaling\n",
    "- Exploratory data analysis\n",
    "- Applications in Python using the AWS platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbf30e4-7dfe-45fc-a480-dc8cad5362d9",
   "metadata": {},
   "source": [
    "# Lesson #1 - Introduction to Data Science and Modeling with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efd4fe1-4102-4f91-bfab-589238ce1a6d",
   "metadata": {},
   "source": [
    "- **Supervised Machine Learning**: In this type of learning, algorithms are trained on datasets where each input example has a clear correspondence with a desired output. The goal is for the model to learn to make accurate predictions or correct classifications for new data based on patterns identified in the training data.\r\n",
    "\r\n",
    "- **Unsupervised Machine Learning**: In contrast to supervised learning, here algorithms are trained on data that do not have pre-determined labels or categories. Instead, the algorithm seeks to identify structures or underlying patterns in the data, such as natural groupings or relationships between variables, without external guidance.\r\n",
    "\r\n",
    "- **Semi-Supervised Machine Learning**: This method combines elements of both supervised and unsupervised learning. The model is trained on a dataset that includes both labeled and unlabeled examples. This allows the algorithm to leverage the information from labeled data to guide learning, while also exploring patterns in unlabeled data to improve performance.\r\n",
    "\r\n",
    "- **Reinforcement Learning**: In this paradigm, algorithms learn from interacting with an environment, taking actions and receiving feedback in the form of rewards or penalties. The goal is for the agent to learn to make the best possible decisions to maximize cumulative reward over time, dynamically adapting to changes in the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019c1d0e-76d7-4b03-a826-3ded05a35f96",
   "metadata": {},
   "source": [
    "## Data Science Project Lifecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bc1a15-3d0d-4b33-9e77-6f7080b3a6ee",
   "metadata": {},
   "source": [
    "- **Business Problem**: Define the problem and available resources; Formulate hypotheses to test.\n",
    "- **Data Collection**: Gathering data for the project.\n",
    "- **Data Preparation & Exploratory Data Analysis (EDA)**: Data preparation and cleaning. Exploratory data analysis.\n",
    "- **Model Learning (Data Modeling)**: Training and modeling the data using machine learning algorithms.\n",
    "- **Model Evaluation**: Assessing the quality of results with appropriate metrics.\n",
    "- **Model Deployment**: Implementing the solution and reporting results to key stakeholders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd414fc6-38ff-4a8c-9cc5-1d19de8f15d6",
   "metadata": {},
   "source": [
    "- https://pandas.pydata.org/\n",
    "- https://numpy.org/\n",
    "- https://matplotlib.org/\n",
    "- https://seaborn.pydata.org/\n",
    "- https://scikit-learn.org/stable/\n",
    "- https://jupyter.org/\n",
    "- https://www.anaconda.com/products/individual\n",
    "- https://www.spyder-ide.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445e2290-2935-4bee-9bf6-41b0ff00345b",
   "metadata": {},
   "source": [
    "### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644507f9-a157-439a-8e21-7b3504fbe440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = {'Nome': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "        'Idade': [25, 30, 35, 28],\n",
    "        'Cidade': ['Nova York', 'Los Angeles', 'Chicago', 'Houston']}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6f4f2d-83ec-45d6-9e42-b7389a1c4ce1",
   "metadata": {},
   "source": [
    "### NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8705ca-0f09-4ded-9c08-cd6128fe1159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "shape = (12, 3)\n",
    "dataset = np.random.randint(0, 100, size=shape)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b731b63c-e348-46f8-8562-ced660ee9eeb",
   "metadata": {},
   "source": [
    "### NumPy -> Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59e9f88-7a5a-49a7-a93d-8f5153d42f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(dataset, columns=['Column1', 'Column2', 'Column3'])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0502c3bd-6418-4af6-b7bf-6f96b3a79bc0",
   "metadata": {},
   "source": [
    "### data_range and set_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24ec251-c2c2-45d4-8faa-bda7966a401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inicial = '2023-01-01'\n",
    "periodo = pd.date_range(start=data_inicial, periods=12, freq='M')\n",
    "df['Data'] = periodo\n",
    "df.set_index('Data', inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b711fe8-09ba-4499-92f7-3c802d4e1619",
   "metadata": {},
   "source": [
    "### Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463127fe-05b0-45c2-ab2e-fba8f476e4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "for coluna in df.columns:\n",
    "    plt.plot(df.index, df[coluna], label=coluna)\n",
    "plt.title('Gr√°fico de Linhas')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fa3c39-c534-43cc-a130-b59263a69295",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78414db-b7a9-41cc-9485-ab3c977cc091",
   "metadata": {},
   "source": [
    "- **Exercice 1.1**: Create a DataFrame in Python with fictitious information for four employees, containing the columns \"Name\", \"Age\", and \"Salary\", and perform the following operations:\n",
    "    - a) Calculate the average age of the employees.\n",
    "    - b) Find the youngest employee.\n",
    "    - c) Sort the employees in descending order of salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c891448e-4e7a-43c7-8ed3-2c6f06337fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with fictitious information for four employees\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "        'Age': [25, 30, 35, 28],\n",
    "        'Salary': [50000, 28000, 37000, 15000]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate the average age of the employees\n",
    "average_age = df['Age'].mean()\n",
    "print(\"Average age of employees:\", average_age)\n",
    "\n",
    "# Find the youngest employee\n",
    "youngest_employee = df.loc[df['Age'].idxmin()]\n",
    "print(\"Youngest employee:\")\n",
    "print(youngest_employee)\n",
    "\n",
    "# Sort the employees in descending order of salary\n",
    "sorted_df = df.sort_values(by='Salary', ascending=False)\n",
    "print(\"Employees sorted by salary (descending):\")\n",
    "print(sorted_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6492ed-de4b-439e-a887-f048f8347804",
   "metadata": {},
   "source": [
    "- **Exercice 1.2**: Create a vector (array) in Python using the NumPy library, containing the integers from 1 to 10 inclusive. Then, perform the following operations:\n",
    "    - a) Calculate the sum of the elements of the vector.\n",
    "    - b) Calculate the mean of the elements of the vector.\n",
    "    - c) Find the maximum value of the vector.\n",
    "    - d) Replace all even numbers in the vector with -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aec562-e73d-4fa6-bb26-7e597872ab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a vector containing integers from 1 to 10\n",
    "vector = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "# Calculate the sum of the elements of the vector\n",
    "sum_vector = np.sum(vector)\n",
    "print(\"Sum of the elements of the vector:\", sum_vector)\n",
    "\n",
    "# Calculate the mean of the elements of the vector\n",
    "mean_vector = np.mean(vector)\n",
    "print(\"Mean of the elements of the vector:\", mean_vector)\n",
    "\n",
    "# Find the maximum value of the vector\n",
    "max_value = np.max(vector)\n",
    "print(\"Maximum value of the vector:\", max_value)\n",
    "\n",
    "# Replace all even numbers in the vector with -1\n",
    "vector[vector % 2 == 0] = -1\n",
    "print(\"Vector with even numbers replaced by -1:\", vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f29eaca-93a6-4b74-8014-bdd4fcd27d54",
   "metadata": {},
   "source": [
    "# Lesson #2 - Importing, Representing and Visualizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a08238-31d9-40ab-b9a5-233a0b957c93",
   "metadata": {},
   "source": [
    "## Types of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e37587e-d673-42aa-92d3-6be07758fe6f",
   "metadata": {},
   "source": [
    "### Numeric Data versus Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa02e93-11ae-473c-8adc-142563dcb0d9",
   "metadata": {},
   "source": [
    "- **Numeric data** can be divided into:\n",
    "    - **Continuous Data** - take any numeric value within a measurable interval.\n",
    "    - **Discrete Data** - take any countable integer numeric value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1a8064-6d43-4374-bdf9-4daa192b2a25",
   "metadata": {},
   "source": [
    "- **Categorical data** are statistical data represented by a finite number of distinct categories or groups. They can be divided into:\n",
    "    - **Nominal Data** - represent categories or groups without any specific order.\n",
    "    - **Ordinal Data** - represent categories or groups that have an associated specific order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa20729-0883-4ffa-87b6-0e4cf803c24e",
   "metadata": {},
   "source": [
    "### Temporal Data, Cross-Sectional Data, and Panel Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b381aea-acc1-4621-918c-6a0e2708a012",
   "metadata": {},
   "source": [
    "- **Temporal data** or **time series** represent sequentially ordered observations over time (daily stock prices of Microsoft from 2020-2022).\n",
    "- **Cross-sectional data** represent information from various sample units (individuals, customers, companies, cities, clubs).\n",
    "- **Panel data** or **longitudinal data** have both temporal and cross-sectional dimensions (macroeconomic indicators of Eurozone countries over a certain period)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d52d509-ddd5-443f-b706-1d267740a691",
   "metadata": {},
   "source": [
    "### Structured Data versus Unstructured Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a2de46-7603-46c2-8845-12f437deed3b",
   "metadata": {},
   "source": [
    "- **Structured data** are data that are typically organized and stored in databases, spreadsheets, or text files (sales of products and services, customer data, article data).\n",
    "- **Unstructured data** are data that are not organized in predefined formats. Examples include text, images, videos, and audio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a631533-651b-483c-8487-fbde5a83cfa7",
   "metadata": {},
   "source": [
    "## Data Importation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4b8092-b4b5-4763-b3a5-93465d27e596",
   "metadata": {},
   "source": [
    "ML models are fed by data represented in the form of tables or matrices. The formats can be: Excel (.xls or .xlsx), CSV (.csv), or Text (.txt).\n",
    "Example: Housing prices in various suburbs of the United States. [Housing prices USA](https://raw.githubusercontent.com/vikram-bhati/Project-house-price-prediction/master/USA_Housing.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642404da-5645-4df7-a90b-74ee13c6fa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "url = \"https://raw.githubusercontent.com/vikram-bhati/Project-house-price-prediction/master/USA_Housing.csv\"\n",
    "df = pd.read_csv(url, header=0)\n",
    "print(df.shape)\n",
    "print(df.head)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d981385-f8ae-4b04-b3e3-33f59b42675f",
   "metadata": {},
   "source": [
    "### Data Importation from Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdce30dc-72de-4293-8c1e-49634eb46612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = r\"C:\\Users\\Miguel Caldeira\\Documents\\GitHub\\Postgrad_AI_ML\\Postgrad_AI_Data_Modeling\\Data_Excel_Example1.xlsx.xlsx\"\n",
    "sheet_name = 'Sheet1'\n",
    "df = pd.read_excel(data, sheet_name=sheet_name)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c801c112-efc4-4ef4-8469-97dec7b66ff6",
   "metadata": {},
   "source": [
    "### Reading Data from the Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c556fcf-8ce5-4dd1-80dd-319079301a41",
   "metadata": {},
   "source": [
    "There are various ways to access data on the internet using Python tools and libraries. For example, the yfinance library provides access to financial data from [Yahoo Finance](https://finance.yahoo.com)\r\n",
    "You can install it using pip:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "588aedc1-924a-4c37-909f-a1a0ee43edf1",
   "metadata": {},
   "source": [
    "pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d75c0d1-83db-4197-8c86-68d0c1ec977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "ticker_symbol = \"GOOGL\"\n",
    "start_date = \"2020-01-01\"\n",
    "end_date = \"2022-12-31\"\n",
    "\n",
    "data = yf.download(ticker_symbol, start=start_date, end=end_date)\n",
    "print(data)\n",
    "\n",
    "data['Close'].plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7881969-9e14-4836-983f-86f1cb97656f",
   "metadata": {},
   "source": [
    "## Graphical Representations of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beb1494-ef99-46ac-b0c4-0b39b3e2763d",
   "metadata": {},
   "source": [
    "In data science, the following types of graphs are common:\n",
    "- line plot\n",
    "- bar chart\n",
    "- histogram\n",
    "- box plot\n",
    "- scatter plot\n",
    "- area chart\n",
    "- heatmap\n",
    "- pie chart\n",
    "- bubble chart\n",
    "- multivariate graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99627ce8-86c3-4be7-b8f9-fae6090f2b7d",
   "metadata": {},
   "source": [
    "### Line Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86b3a70-59de-43c3-892c-fa65c3889433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Carregar dados de um conjunto de dados aberto\n",
    "url = 'https://raw.githubusercontent.com/datasets/gdp/master/data/gdp.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Plotar o PIB (GDP) dos Estados Unidos ao longo do tempo\n",
    "usa_gdp = data[data['Country Name'] == 'United States']['Value']\n",
    "years = data[data['Country Name'] == 'United States']['Year']\n",
    "\n",
    "plt.plot(years, usa_gdp)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('GDP (in Trillion USD)')\n",
    "plt.title('US GDP Over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8ea1fe-58ac-4764-b12c-d7531b50f3f0",
   "metadata": {},
   "source": [
    "### Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cb2344-3260-45ee-962d-33ad726fe58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "months = ['jan','feb','mar','apr','may']\n",
    "sales = [100, 150, 260, 450, 500]\n",
    "plt.bar(months, sales)\n",
    "plt.xlabel('Months')\n",
    "plt.ylabel('Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb4dd6c-ebe3-46ff-b65d-26a87f4c3e29",
   "metadata": {},
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c164de30-162b-4454-b810-8653b626afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.random.normal(0, 1, 1000)\n",
    "\n",
    "plt.hist(data, bins=30)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram Example')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382faa1f-f599-478a-a582-8e7e92cd78cb",
   "metadata": {},
   "source": [
    "### Box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d5d01d-4855-4916-b02e-40c15b7e08ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "age = (28, 35, 95, 19, 21, 45, 51, 37)\n",
    "plt.boxplot(age)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3de21e-df98-422c-94ca-3e41c2fa54e1",
   "metadata": {},
   "source": [
    "### Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7230bee-0e2d-48f2-b5e7-c447419d3549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "age = (28, 35, 95, 19, 21)\n",
    "purchases = (200, 150, 125, 250, 275)\n",
    "gender = ('M', 'F','F','M','F')\n",
    "colors = ('b','r','r','b','r')\n",
    "label = {'b': 'Male', 'r':'Female'}\n",
    "legend = [label[c] for c in colors]\n",
    "plt.scatter(age, purchases, c=colors, label=label)\n",
    "plt.legend(legend)\n",
    "plt.title(\"Scatter of Age vs Purchase Value\")\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fc68f9-b324-49ed-ae77-802e3cec9aed",
   "metadata": {},
   "source": [
    "### Area Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767951b7-bde1-4729-a0d0-bb30284b9054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [1, 4, 9, 16, 25]\n",
    "\n",
    "plt.fill_between(x, y)\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Area Chart Example')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea20bedf-3ecc-4daf-bea9-9ad5112919e7",
   "metadata": {},
   "source": [
    "### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4777c699-dc91-436c-a5e5-b39bf9a17d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data = np.random.rand(10, 10)\n",
    "\n",
    "plt.imshow(data, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('Heatmap Example')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941ede06-e8f7-4458-86ab-f22aab1251a3",
   "metadata": {},
   "source": [
    "### Pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6f6d80-91cb-4f48-8321-bb471e4899d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sizes = [15, 30, 45, 10]\n",
    "labels = ['A', 'B', 'C', 'D']\n",
    "\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%')\n",
    "plt.title('Pie Chart Example')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4427ce-2596-4116-a8ed-53e570b83539",
   "metadata": {},
   "source": [
    "### Bubble Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59cf3f1-41be-439b-b220-e11de8cc5b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.random.rand(50)\n",
    "y = np.random.rand(50)\n",
    "sizes = np.random.rand(50) * 1000\n",
    "\n",
    "plt.scatter(x, y, s=sizes)\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Bubble Chart Example')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec548fe0-c7a2-427e-91e2-a72f74c37926",
   "metadata": {},
   "source": [
    "### Correlation between age and purchase value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911abe1a-b7c6-4c27-a294-4fd92661a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "age = (28, 35, 95, 19, 21, 18, 25, 55)\n",
    "purchases = (200, 150, 125, 250, 275, 400, 300, 175)\n",
    "corr, p_value = np.corrcoef(age, purchases)\n",
    "print(corr)\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d45003-cdc9-43b3-b467-8c8d92c0d1d2",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae6b976-e931-4aee-81db-1febe534fda0",
   "metadata": {},
   "source": [
    "- **Execise 2.1** Create a bar chart for the monthly sales of a fictional product ABC over 12 months. Use the Python Matplotlib library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e66297-3b0e-4ebd-854b-eaa35ef787b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Monthly sales data for the fictional product ABC\n",
    "months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "sales = [1000, 1200, 1500, 1300, 1400, 1600, 1700, 1800, 1900, 2000, 2100, 2200]\n",
    "\n",
    "# Create a bar chart\n",
    "plt.bar(months, sales, color='blue')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Sales')\n",
    "plt.title('Monthly Sales of Product ABC')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef22d70-f0f7-42cd-9f4a-2136a82e8d33",
   "metadata": {},
   "source": [
    "- **Exercise 2.2** Create a scatter plot showing the relationship between age and total purchase value of 5 customers, based on the following data:\n",
    "    - age = (28, 35, 55, 19, 21)\n",
    "    - purchases = (200, 150, 125, 250, 275)\n",
    "    - gender = ('M', 'F', 'F', 'M', 'F')\n",
    "    - Use different colors to represent the gender (male/female) of the customers. Use the Python Matplotlib library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91f3632-13dc-435c-bd04-5417a417d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Customer data\n",
    "age = (28, 35, 55, 19, 21)\n",
    "purchases = (200, 150, 125, 250, 275)\n",
    "gender = ('M', 'F', 'F', 'M', 'F')\n",
    "\n",
    "# Create a scatter plot\n",
    "colors = {'M': 'blue', 'F': 'red'}\n",
    "plt.scatter(age, purchases, c=[colors[gen] for gen in gender], label=gender)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Total Purchase Value')\n",
    "plt.title('Relationship between Age and Total Purchase Value')\n",
    "plt.legend(title='Gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb25823-c9df-4183-be00-c92ab4ebf1ac",
   "metadata": {},
   "source": [
    "- **Exercise 2.3** Import the monthly number of air passengers in the USA from January 1949 to December 1960 using the Seaborn library in Python and create a line plot to represent the number of air passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84573a4-2617-4217-bf10-1df954e640c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Import the data\n",
    "data = sns.load_dataset(\"flights\")\n",
    "\n",
    "# Create a line plot\n",
    "sns.lineplot(data=data, x='year', y='passengers')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Passengers')\n",
    "plt.title('Monthly Number of Air Passengers in the USA (1949-1960)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52660ee-375c-4eac-ae1c-b5f68b9c0a44",
   "metadata": {},
   "source": [
    "# Lesson #3: Data Cleaning and Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b661699-0734-4f45-9d2c-3c115c3de8e9",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7661bc48-dabe-468a-a4fe-5b9562f3bdee",
   "metadata": {},
   "source": [
    "**Missing Data**\n",
    "- The presence of missing data in a database can occur for various reasons:\n",
    "    - Failures in data collection\n",
    "    - Unavailability\n",
    "    - Ignorance\n",
    "    - Errors in data reading\n",
    "\n",
    "- What to do in the presence of missing data? The answer depends on the structure and size of the data and the context of the project.\n",
    "    - Remove the data\n",
    "    - Impute the missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d099b313-4984-492f-9e12-fa7a1f283acf",
   "metadata": {},
   "source": [
    "### Remove the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addf0de2-1b5d-4e7b-aa7d-86308c06eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample dataframe with missing data\n",
    "data = {'A': [1, 2, None, 4, 5],\n",
    "        'B': [None, 2, 3, 4, 5],\n",
    "        'C': [1, 2, 3, None, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Remove rows with missing values\n",
    "cleaned_df = df.dropna()\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nDataFrame after removing rows with missing values:\")\n",
    "print(cleaned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b39bfde-7942-4955-8428-df6fb22d9ec3",
   "metadata": {},
   "source": [
    "### Missing Data - Impute Mean and Median:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762466e3-a777-4fcf-9bcc-87081f411a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample dataframe with missing data\n",
    "data = {'A': [1, 2, None, 4, 5],\n",
    "        'B': [None, 2, 3, 4, 5],\n",
    "        'C': [1, 2, 3, None, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Impute missing values with mean\n",
    "mean_imputed_df = df.fillna(df.mean())\n",
    "\n",
    "# Impute missing values with median\n",
    "median_imputed_df = df.fillna(df.median())\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nDataFrame after imputing missing values with mean:\")\n",
    "print(mean_imputed_df)\n",
    "print(\"\\nDataFrame after imputing missing values with median:\")\n",
    "print(median_imputed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce66ade-08b2-4c14-ba3f-cffd73705c3b",
   "metadata": {},
   "source": [
    "### Missing Data - Impute the mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d4dc9f-04dc-4ee9-a39f-7a40d1211318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample dataframe with missing data\n",
    "data = {'A': [1, 2, None, 4, 5],\n",
    "        'B': [None, 2, 3, 4, 5],\n",
    "        'C': [1, 2, 3, None, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Impute missing values with mode\n",
    "mode_imputed_df = df.fillna(df.mode().iloc[0])\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nDataFrame after imputing missing values with mode:\")\n",
    "print(mode_imputed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81903b1e-1f9d-4bac-8bc4-f068b428675f",
   "metadata": {},
   "source": [
    "### Missing Data - Interpolation (temporal data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aae3eb-2381-4dae-b5a8-14a364879e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample dataframe with temporal data and missing values\n",
    "dates = pd.date_range(start='2024-01-01', periods=20)\n",
    "data = {'Value': [1, 2, np.nan, 7, 8, np.nan, 12, 15, 18, np.nan, 22, 25, 30, np.nan, 35, 40, 45, np.nan, 50, 55]}\n",
    "df = pd.DataFrame(data, index=dates)\n",
    "\n",
    "# Interpolate missing values\n",
    "interpolated_df = df.interpolate(method='linear')\n",
    "\n",
    "# Plot original and interpolated time series\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df.index, df['Value'], marker='o', label='Original', color='blue')\n",
    "plt.plot(interpolated_df.index, interpolated_df['Value'], marker='x', linestyle='--', label='Interpolated', color='green')\n",
    "plt.title('Original vs Interpolated Time Series')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db03bf8-56dc-4695-95dc-d1cfc36dbb6e",
   "metadata": {},
   "source": [
    "### Outlier Detection and \"Correction\":"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13da6a0e-0fe9-4f4b-9873-844b77c3f96a",
   "metadata": {},
   "source": [
    "\"Outliers are observations in numerical data that significantly deviate from other observations and can cause distortions...\" (Caiado, J., Ed. S√≠labo 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250c1e47-7fad-4b82-8a93-01c3349268b3",
   "metadata": {},
   "source": [
    "### Boxplot Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f5db2d-b698-46da-b920-e7b700fe4040",
   "metadata": {},
   "source": [
    "Identify in a box plot the observations (or points) that are above or below the majority of the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37e54e1-d8d4-4c77-bf8e-7ddf4c025c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate sample data with outliers\n",
    "np.random.seed(123)\n",
    "data = np.random.normal(loc=0, scale=1, size=100)\n",
    "data[95:] = data[95:] + 10  # Adding outliers\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=['Values'])\n",
    "\n",
    "# Plot boxplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(df['Values'], vert=False)\n",
    "plt.title('Boxplot of Data with Outliers')\n",
    "plt.xlabel('Values')\n",
    "plt.yticks([])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1328fd-fef3-4d43-b5b2-e9b7512ab27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate quartiles and IQR\n",
    "Q1 = df['Values'].quantile(0.25)\n",
    "Q3 = df['Values'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculate outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "outliers = df[(df['Values'] < lower_bound) | (df['Values'] > upper_bound)]['Values']\n",
    "\n",
    "print(\"Minimum:\", df['Values'].min())\n",
    "print(\"First Quartile (Q1):\", Q1)\n",
    "print(\"Median (Q2):\", df['Values'].median())\n",
    "print(\"Third Quartile (Q3):\", Q3)\n",
    "print(\"Maximum:\", df['Values'].max())\n",
    "print(\"Outliers:\", outliers.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fece91b8-3631-4b76-a380-53a8d1680d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate sample data with outliers\n",
    "np.random.seed(123)\n",
    "data = np.random.normal(loc=0, scale=1, size=100)\n",
    "data[95:] = data[95:] + 10  # Adding outliers\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=['Values'])\n",
    "\n",
    "# Identify outliers\n",
    "Q1 = df['Values'].quantile(0.25)\n",
    "Q3 = df['Values'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "outliers = df[(df['Values'] < lower_bound) | (df['Values'] > upper_bound)]\n",
    "\n",
    "# Plot boxplot without outliers\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(df['Values'][~df['Values'].isin(outliers['Values'])], vert=False)\n",
    "plt.title('Boxplot without Outliers')\n",
    "plt.xlabel('Values')\n",
    "plt.yticks([])\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c2af0e-ad86-4e26-a5ad-9e7b561cc3eb",
   "metadata": {},
   "source": [
    "### Standard Deviation Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96e7c65-6308-479d-b85c-c5b6213318dd",
   "metadata": {},
   "source": [
    "- This method identifies observations or points that deviate from the mean by a certain number of standard deviations (usually 2 or 3) as outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a1152c-6dce-46b9-9d98-38be09e65b4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dados\n",
    "dados = np.array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 30, 31, 30, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10])\n",
    "\n",
    "# C√°lculo da m√©dia e do desvio padr√£o\n",
    "media = np.mean(dados)\n",
    "desvio_padrao = np.std(dados)\n",
    "\n",
    "# Limites m√≠nimo e m√°ximo\n",
    "limite_min = media - 2 * desvio_padrao\n",
    "limite_max = media + 2 * desvio_padrao\n",
    "\n",
    "# Identifica√ß√£o de outliers\n",
    "outliers = dados[(dados < limite_min) | (dados > limite_max)]\n",
    "\n",
    "# Remo√ß√£o de outliers\n",
    "dados_sem_outliers = dados[(dados >= limite_min) & (dados <= limite_max)]\n",
    "\n",
    "# Plotando os dados com outliers\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(dados, 'bo', label='Dados')\n",
    "plt.plot([0, len(dados)], [limite_min, limite_min], 'r--', label='Limite m√≠nimo')\n",
    "plt.plot([0, len(dados)], [limite_max, limite_max], 'r--', label='Limite m√°ximo')\n",
    "plt.plot(np.where(dados < limite_min)[0], dados[dados < limite_min], 'ro', label='Outliers')\n",
    "plt.plot(np.where(dados > limite_max)[0], dados[dados > limite_max], 'ro')\n",
    "plt.xlabel('√çndice dos Dados')\n",
    "plt.ylabel('Valores')\n",
    "plt.title('Dados com Outliers')\n",
    "plt.legend()\n",
    "\n",
    "# Plotando os dados sem outliers\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(dados_sem_outliers, 'go', label='Dados sem outliers')\n",
    "plt.xlabel('√çndice dos Dados')\n",
    "plt.ylabel('Valores')\n",
    "plt.title('Dados Sem Outliers')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953b4292-a3f1-4b46-a846-dd302e0c7efc",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db80dbb-ed90-4ae4-b3bc-c67f3ba5a102",
   "metadata": {},
   "source": [
    "**Exercice 3.1** Consider the following example of a DataFrame created in Python with fictitious data of different types:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29d125e4-905c-4050-a93d-bcb58bd05304",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "data = {'Numerica_Continua1': [5.0, 6.5, 7.2, 8.0, 6.8, None, 5.5, 7.0],\n",
    "        'Numerica_Continua2': [12.1, 14.2, None, 10.5, 13.0, 11.9, 15.2, None],\n",
    "        'Numerica_Binaria': [1, 0, 1, 1, 0, 0, None, 1],\n",
    "        'Categorica_Ordinal': ['Baixo', 'M√©dio', 'Alto', None, 'M√©dio', 'Alto', 'M√©dio', 'Baixo'],\n",
    "        'Categorica_Nominal': ['Lisboa', 'Porto', 'Porto', None, 'Leiria', 'Lisboa', 'Lisboa', '√âvora']}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f826715a-3416-447e-a862-f88d32205519",
   "metadata": {},
   "source": [
    "- Write Python code to fill in the missing values using:\n",
    "    - a) The mean imputation method to impute the missing values of the variable Numerica_Continua1.\n",
    "    - b) The median imputation method to impute the missing values of the variable Numerica_Continua2.\n",
    "    - c) The mode imputation method to impute the missing values of the variables Numerica_Binaria, Categorica_Ordinal, and Categorica_Nominal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a58af9c-525e-4d29-99ea-03a6e2f015f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Given DataFrame\n",
    "data = {'Numerica_Continua1': [5.0, 6.5, 7.2, 8.0, 6.8, None, 5.5, 7.0],\n",
    "        'Numerica_Continua2': [12.1, 14.2, None, 10.5, 13.0, 11.9, 15.2, None],\n",
    "        'Numerica_Binaria': [1, 0, 1, 1, 0, 0, None, 1],\n",
    "        'Categorica_Ordinal': ['Baixo', 'M√©dio', 'Alto', None, 'M√©dio', 'Alto', 'M√©dio', 'Baixo'],\n",
    "        'Categorica_Nominal': ['Lisboa', 'Porto', 'Porto', None, 'Leiria', 'Lisboa', 'Lisboa', '√âvora']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# a) Mean imputation for Numerica_Continua1\n",
    "mean_Numerica_Continua1 = df['Numerica_Continua1'].mean()\n",
    "df['Numerica_Continua1'].fillna(mean_Numerica_Continua1, inplace=True)\n",
    "\n",
    "# b) Median imputation for Numerica_Continua2\n",
    "median_Numerica_Continua2 = df['Numerica_Continua2'].median()\n",
    "df['Numerica_Continua2'].fillna(median_Numerica_Continua2, inplace=True)\n",
    "\n",
    "# c) Mode imputation for Numerica_Binaria, Categorica_Ordinal, and Categorica_Nominal\n",
    "mode_Numerica_Binaria = df['Numerica_Binaria'].mode()[0]\n",
    "df['Numerica_Binaria'].fillna(mode_Numerica_Binaria, inplace=True)\n",
    "\n",
    "mode_Categorica_Ordinal = df['Categorica_Ordinal'].mode()[0]\n",
    "df['Categorica_Ordinal'].fillna(mode_Categorica_Ordinal, inplace=True)\n",
    "\n",
    "mode_Categorica_Nominal = df['Categorica_Nominal'].mode()[0]\n",
    "df['Categorica_Nominal'].fillna(mode_Categorica_Nominal, inplace=True)\n",
    "\n",
    "# Displaying the resulting DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae6a650-a87a-4a15-8a35-630f2667229f",
   "metadata": {},
   "source": [
    "**Exercise 3.2** Using the dataset of a real telemarketing campaign conducted by a Portuguese bank, available through the link [here](https://raw.githubusercontent.com/TrainingByPackt/Data-Science-with-Python/master/Chapter01/Data/Banking_Marketing.csv), use Python to remove missing observations and proceed with outlier detection and removal in the variable \"age\" using:\n",
    "- a) Boxplot method\n",
    "- b) Standard deviation method (considering 4 standard deviations from the mean as the threshold value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b633b57-3c73-4f13-bfeb-2bd54af61fd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/TrainingByPackt/Data-Science-with-Python/master/Chapter01/Data/Banking_Marketing.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Step 2: Remove missing observations\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Step 3a: Outlier detection and removal using the boxplot method\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(x=data['age'])\n",
    "plt.title('Age Distribution (with Outliers)')\n",
    "\n",
    "# Calculate Interquartile Range (IQR)\n",
    "Q1 = data['age'].quantile(0.25)\n",
    "Q3 = data['age'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define lower and upper bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Remove outliers\n",
    "data_boxplot_filtered = data[(data['age'] >= lower_bound) & (data['age'] <= upper_bound)]\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x=data_boxplot_filtered['age'])\n",
    "plt.title('Age Distribution (without Outliers)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 3b: Outlier detection and removal using the standard deviation method\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(data['age'], kde=True)\n",
    "plt.title('Age Distribution (with Outliers)')\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_age = data['age'].mean()\n",
    "std_dev_age = data['age'].std()\n",
    "\n",
    "# Define lower and upper bounds using 4 standard deviations from the mean\n",
    "lower_bound_std = mean_age - 4 * std_dev_age\n",
    "upper_bound_std = mean_age + 4 * std_dev_age\n",
    "\n",
    "# Remove outliers\n",
    "data_std_filtered = data[(data['age'] >= lower_bound_std) & (data['age'] <= upper_bound_std)]\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(data_std_filtered['age'], kde=True)\n",
    "plt.title('Age Distribution (without Outliers)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the number of outliers removed using both methods\n",
    "outliers_removed_boxplot = len(data) - len(data_boxplot_filtered)\n",
    "outliers_removed_std = len(data) - len(data_std_filtered)\n",
    "\n",
    "print(\"Number of outliers removed using Boxplot method:\", outliers_removed_boxplot)\n",
    "print(\"Number of outliers removed using Standard Deviation method:\", outliers_removed_std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3de46b4-7806-46e1-80b2-c09387b2973e",
   "metadata": {},
   "source": [
    "# Lesson #4: Data Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40df7eb-494b-42bb-916e-003a58b65f25",
   "metadata": {},
   "source": [
    "## Data Encoding\n",
    "- One of the main challenges for a data scientist in the data preparation stage is the conversion of categorical data into numerical data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a3d88c-6e1c-4a79-90c9-edffe220f638",
   "metadata": {},
   "source": [
    "### Label Encoding\n",
    "- This method of label encoding assigns a number to each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5d72ea-5817-41f3-92ce-72ea8edc4d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Categorical data representing various professions\n",
    "professions = ['Doctor','Engineer','Teacher','Lawyer',\n",
    "'Doctor','Footballer','Teacher','Engineer','Accountant','Lawyer']\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the data\n",
    "encoded_professions = label_encoder.fit_transform(professions)\n",
    "\n",
    "# Display the encoded professions\n",
    "print(\"Encoded Professions:\")\n",
    "for i, profession in enumerate(professions):\n",
    "    print(f\"{profession}: {encoded_professions[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde59a61-016c-464e-b5ec-a3b5e7465136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Ordinal categorical data representing satisfaction levels\n",
    "satisfaction_levels = ['Unsatisfied','Satisfied','VerySatisfied','Satisfied', 'Very Satisfied', 'Unsatisfied','LessSatisfied',\n",
    "'Very Satisfied', 'Satisfied', 'Unsatisfied']\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the data\n",
    "encoded_satisfaction_levels = label_encoder.fit_transform(satisfaction_levels)\n",
    "\n",
    "# Display the encoded satisfaction levels\n",
    "print(\"Encoded Satisfaction Levels:\")\n",
    "for i, satisfaction_level in enumerate(satisfaction_levels):\n",
    "    print(f\"{satisfaction_level}: {encoded_satisfaction_levels[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d23a1c2-dfaf-4ad9-8dab-26e7fcf47962",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052a4f5e-3311-4f9f-a732-b09fd2685078",
   "metadata": {},
   "source": [
    "- Creating a binary variable for each category that takes the values 1 or 0 depending on whether the object belongs to that category or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033ee418-ec75-4905-b9a8-7831804b7ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data\n",
    "data = {'Cities': ['Paris', 'Rome', 'Lisbon', 'Madrid', 'Lisbon', 'Madrid', 'Lisbon', 'Paris', 'Lisbon']}\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# One-hot encoding using pandas get_dummies() with integer dtype\n",
    "one_hot_encoded_data = pd.get_dummies(df['Cities'], dtype=int)\n",
    "\n",
    "# Concatenate the one-hot encoded data with the original DataFrame\n",
    "encoded_df = pd.concat([df, one_hot_encoded_data], axis=1)\n",
    "\n",
    "# Display the encoded DataFrame\n",
    "print(\"Encoded Data:\")\n",
    "print(encoded_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9b9813-5087-43b1-8d90-0bb352079672",
   "metadata": {},
   "source": [
    "### TargetEncoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ffea5-7aa0-4ccf-ba9c-45f555548806",
   "metadata": {},
   "source": [
    "- Encoding of categorical variables that allow mapping each category with baselines of location statistics (typically, mean or median) of the target variable associated with that category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae73db4-c9fb-4639-bc23-07442013cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movie data and their respective scores\n",
    "data = {'Movie': ['A', 'B', 'A', 'C', 'B', 'C', 'A', 'B','C'],\n",
    "'Score': [5, 4, 3, 4, 4, 5, 3, 4, 4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31727f65-fed0-48e0-b67b-1ce130404b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Movie data and their respective scores\n",
    "data = {'Movie': ['A', 'B', 'A', 'C', 'B', 'C', 'A', 'B','C'],\n",
    "        'Score': [5, 4, 3, 4, 4, 5, 3, 4, 4]}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate mean score for each movie\n",
    "mean_scores = df.groupby('Movie')['Score'].mean()\n",
    "\n",
    "# Map mean scores to movies and create a new column\n",
    "df['TargetEncoded_Movie'] = df['Movie'].map(mean_scores)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8357d2-9922-408d-a5c0-49a988941084",
   "metadata": {},
   "source": [
    "## Standardization and Normalization of Data\n",
    "- Transformation of data to a common scale or magnitude, ensuring that all variables have the same order of magnitude and relevance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f338545c-0851-4c32-a3ca-2af77bb2dd45",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f228eca8-6df4-4db7-a2d5-21d32371699e",
   "metadata": {},
   "source": [
    "- Subtracting each observed value of a variable by its minimum value and then dividing the result by the difference between the maximum and minimum: ùëåùëñ = ùëãùëñ‚àímin(ùëã) / max(ùëã)‚àímin(ùëã)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e6576-4487-42c7-aa14-b0b4a60c5bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'Age': [25, 30, 35, 40, 45],\n",
    "        'Salary': [40000, 52000, 60000, 75000, 200000]}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Normalize the data\n",
    "normalized_data = (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "print(normalized_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68039d9b-c6f9-4881-9f84-6449e2f502fa",
   "metadata": {},
   "source": [
    "### Data Standardization\n",
    "- Subtracting the mean from the observed data and dividing the result by the standard deviation, in order to obtain a new variable with a mean of 0 and a standard deviation of 1:\n",
    "ùëåùëñ = ùëãùëñ‚àíùúáùëã / ùúéùëã(ùëã)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e886bac-c6e6-44c8-bbe8-f6bde44493c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {'Age': [25, 30, 35, 40, 45],\n",
    "        'Salary': [40000, 52000, 60000, 75000, 200000]}\n",
    "\n",
    "# Calculate mean and standard deviation for each feature\n",
    "mean_age = np.mean(data['Age'])\n",
    "std_age = np.std(data['Age'])\n",
    "mean_salary = np.mean(data['Salary'])\n",
    "std_salary = np.std(data['Salary'])\n",
    "\n",
    "# Standardize the data\n",
    "standardized_data = {\n",
    "    'Age': [(x - mean_age) / std_age for x in data['Age']],\n",
    "    'Salary': [(x - mean_salary) / std_salary for x in data['Salary']]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the standardized data\n",
    "df_standardized = pd.DataFrame(standardized_data)\n",
    "\n",
    "print(df_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e4b2ce-2aa6-4cb2-9cce-8ca6579530d9",
   "metadata": {},
   "source": [
    "- In the context of data analysis, one of the frequent questions is the decision on which transformation to carry out: data normalization or data standardization?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b12c09-b6e1-47c8-948e-1a29e42b8f11",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca59a05-074a-4c0e-a667-27b226bd6da9",
   "metadata": {},
   "source": [
    "- **Exercise 4.1** Consider the following hypothetical data of the annual business volume (in millions of euros) of 10 gas stations located in the municipalities of Cascais, Oeiras, and Sintra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aff9ad-3ae4-4ca8-b39f-c2b92511e059",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'concelho': ['Cascais', 'Sintra', 'Sintra', 'Oeiras', 'Cascais', 'Sintra', 'Oeiras', 'Sintra', 'Sintra', 'Cascais'],\n",
    "        'vol_negocios': [12.5, 9.6, 10.1, 14.9, 15.8, 7.5, 12.6, 4.8, 9.9, 17.8]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c239c0f-c41b-4705-82f0-2aa4e596455b",
   "metadata": {},
   "source": [
    "- a) Convert the classes of the categorical variable \"concelho\" into numerical values from 0 to ùëö‚àí1 (where ùëö is the number of distinct classes).\n",
    "- b) Convert the classes of the categorical variable \"concelho\" into ùëö‚àí1 binary variables (0/1).\n",
    "- c) Use the Target Encoding method to replace each class of the categorical variable \"concelho\" with the mean of the corresponding business volume (target variable) associated with that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55faf536-286b-49f0-94bb-25c27f704f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "\r\n",
    "data = {'concelho': ['Cascais', 'Sintra', 'Sintra', 'Oeiras', 'Cascais', 'Sintra', 'Oeiras', 'Sintra', 'Sintra', 'Cascais'],\r\n",
    "        'vol_negocios': [12.5, 9.6, 10.1, 14.9, 15.8, 7.5, 12.6, 4.8, 9.9, 17.8]}\r\n",
    "\r\n",
    "# Convertendo o dicion√°rio para um DataFrame\r\n",
    "df = pd.DataFrame(data)\r\n",
    "\r\n",
    "# a) Convertendo as classes da vari√°vel categ√≥rica \"concelho\" em valores num√©ricos de 0 a ùëö‚àí1\r\n",
    "label_encoder = LabelEncoder()\r\n",
    "df['concelho_numerico'] = label_encoder.fit_transform(df['concelho'])\r\n",
    "\r\n",
    "print(\"a) Converted categorical variable 'concelho' to numerical values:\")\r\n",
    "print(df['concelho_numerico'])\r\n",
    "\r\n",
    "# b) Convertendo as classes da vari√°vel categ√≥rica \"concelho\" em ùëö‚àí1 vari√°veis bin√°rias (0/1)\r\n",
    "one_hot_encoded = pd.get_dummies(df['concelho'])\r\n",
    "\r\n",
    "# Removendo uma das vari√°veis bin√°rias para evitar a multicolinearidade\r\n",
    "one_hot_encoded.drop(columns=one_hot_encoded.columns[-1], inplace=True)\r\n",
    "\r\n",
    "print(\"\\nb) Converted categorical variable 'concelho' to binary variables:\")\r\n",
    "print(one_hot_encoded)\r\n",
    "\r\n",
    "# c) Usando o m√©todo de Target Encoding para substituir cada classe da vari√°vel categ√≥rica \"concelho\"\r\n",
    "# pela m√©dia do volume de neg√≥cios correspondente a essa classe\r\n",
    "mean_vol_negocios = df.groupby('concelho')['vol_negocios'].mean().reset_index()\r\n",
    "mean_vol_negocios.columns = ['concelho', 'mean_vol_negocios']\r\n",
    "df = pd.merge(df, mean_vol_negocios, on='concelho', how='left')\r\n",
    "\r\n",
    "print(\"\\nc) Replaced categorical variable 'concelho' with mean business volume for each category:\")\r\n",
    "print(df[['concelho', 'mean_vol_negocios']])\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a1028c-3392-468b-8e7d-f4c4b773de8f",
   "metadata": {},
   "source": [
    "- **Exercise 4.2** 4.2 Consider the following hypothetical data of prices for eight food items: [15, 30, 50, 60, 75, 46, 89, 29]\n",
    "    - a) Proceed with the standardization of the data based on the calculation of the mean and standard deviation. Use the StandardScaler library from scikit-learn (Python).\n",
    "    - b) Proceed with the normalization of the data based on the calculation of the maximum and minimum of the sample. Use the MinMaxScaler library from scikit-learn (Python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c02c3b5-d643-4ab8-96d5-1353d32e03f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Hypothetical data of prices for eight food items\n",
    "data = [15, 30, 50, 60, 75, 46, 89, 29]\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "standardized_data = scaler.fit_transform(np.array(data).reshape(-1, 1))\n",
    "\n",
    "print(\"Standardized data:\")\n",
    "print(standardized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c224902d-5fdd-4f43-8dec-b8578596a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "normalized_data = scaler.fit_transform(np.array(data).reshape(-1, 1))\n",
    "\n",
    "print(\"\\nNormalized data:\")\n",
    "print(normalized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c357fead-7029-4c71-aee8-a1a0875131bf",
   "metadata": {},
   "source": [
    "# Lesson #5: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12caac8b-1f8e-4070-b498-0e0d9b263fe2",
   "metadata": {},
   "source": [
    "## Univariate Analysis\n",
    "- Univariate descriptive statistics represent the set of techniques used to collect, describe, and interpret univariate (numeric and categorical) data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6ced19-23d9-486d-a0f4-e79277804764",
   "metadata": {},
   "source": [
    "### Numeric Data\n",
    "- The most commonly used descriptive statistics are measures of location, dispersion, skewness, and kurtosis.\n",
    "- **Measures of Location**: arithmetic mean, weighted mean, geometric mean, mode, median, quartiles, and percentiles.\n",
    "- **Measures of Dispersion**: sample variance, sample standard deviation, and coefficient of variation.\n",
    "- **Measures of Skewness and Kurtosis**: Pearson's skewness coefficient (mode and median), Fisher's skewness coefficient, Pearson's kurtosis coefficient, and excess kurtosis (Fisher's coefficient or measure)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c0ce84-95e1-4ab7-ac91-19bf3c374da6",
   "metadata": {},
   "source": [
    "### Measures of Location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8455fe54-5e03-46c6-8226-e0f802c98345",
   "metadata": {},
   "source": [
    "- **Arithmetic Mean**: The sum of all values divided by the number of observations.\n",
    "- **Weighted Mean**: The sum of all values multiplied by their respective weights, divided by the sum of the weights.\n",
    "- **Geometric Mean**: The nth root of the product of n values.\n",
    "- **Mode**: The value(s) that occur most frequently in the dataset.\n",
    "- **Median**: The middle value of a dataset when it is ordered in ascending or descending order.\n",
    "- **Quartiles and Percentiles**: Values that divide the dataset into four or one hundred equal parts, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846841c0-cb0c-40c3-a5a4-b39bbead58d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(0)\n",
    "data = np.random.randint(0, 100, 100)\n",
    "print(data)\n",
    "\n",
    "# Measures of Location\n",
    "mean = np.mean(data)\n",
    "weighted_mean = np.average(data, weights=np.arange(1, 101))\n",
    "geometric_mean = np.prod(data) ** (1 / len(data))\n",
    "mode = np.argmax(np.bincount(data))\n",
    "median = np.median(data)\n",
    "quartiles = np.percentile(data, [25, 50, 75])\n",
    "\n",
    "print(\"Measures of Location:\")\n",
    "print(\"Arithmetic Mean:\", mean)\n",
    "print(\"Weighted Mean:\", weighted_mean)\n",
    "print(\"Geometric Mean:\", geometric_mean)\n",
    "print(\"Mode:\", mode)\n",
    "print(\"Median:\", median)\n",
    "print(\"Quartiles:\", quartiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcf90cf-9c97-4624-8432-f9210562aea9",
   "metadata": {},
   "source": [
    "### Measures of Dispersion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d693d9-6b9f-436b-a343-5348d51a0563",
   "metadata": {},
   "source": [
    "- **Sample Variance**: The average of the squared differences between each data point and the mean.\n",
    "- **Sample Standard Deviation**: The square root of the variance.\n",
    "- **Coefficient of Variation**: The ratio of the standard deviation to the mean, expressed as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8284e5f-3a3d-4a63-9eeb-6634ef0596a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate synthetic data\n",
    "data = np.random.normal(loc=50, scale=10, size=1000)\n",
    "print(data[:20])\n",
    "\n",
    "# Compute measures of dispersion\n",
    "sample_variance = np.var(data)\n",
    "sample_std_deviation = np.std(data)\n",
    "coefficient_of_variation = (sample_std_deviation / np.mean(data)) * 100\n",
    "\n",
    "print(\"Measures of Dispersion:\")\n",
    "print(\"Sample Variance:\", sample_variance)\n",
    "print(\"Sample Standard Deviation:\", sample_std_deviation)\n",
    "print(\"Coefficient of Variation (%):\", coefficient_of_variation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c002fa38-18e0-4c7d-9496-a6321aa8f31b",
   "metadata": {},
   "source": [
    "### Measures of Skewness and Kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea7018-1d88-481d-8462-ff200c15fad9",
   "metadata": {},
   "source": [
    "- **Pearson's Skewness Coefficient**: The third standardized moment, which measures the asymmetry of the distribution. It compares the mode and median of the dataset.\n",
    "- **Fisher's Skewness Coefficient**: Another measure of asymmetry, which is based on the third moment and the standard deviation.\n",
    "- **Pearson's Kurtosis Coefficient**: The fourth standardized moment, which measures the peakedness or flatness of the distribution.\n",
    "- **Excess Kurtosis (Fisher's coefficient or measure)**: The difference between the kurtosis and the normal kurtosis (3 for normal distribution). It provides information about the tails of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08477cef-52f1-46af-8119-03935d3a8a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Generate synthetic data\n",
    "data = np.random.normal(loc=0, scale=1, size=1000)\n",
    "print(data[:20])\n",
    "\n",
    "# Compute skewness and kurtosis\n",
    "skewness = skew(data)\n",
    "kurt = kurtosis(data)\n",
    "\n",
    "# Compute excess kurtosis\n",
    "excess_kurtosis = kurt - 3\n",
    "\n",
    "print(\"Skewness:\", skewness)\n",
    "print(\"Kurtosis:\", kurt)\n",
    "print(\"Excess Kurtosis:\", excess_kurtosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aae07d-de64-41c2-b64e-6c7005b57a23",
   "metadata": {},
   "source": [
    "### Categorical Data\n",
    "- The most common descriptive statistics are count, percentage, and mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3dcaa8-f7a2-4400-85f6-09a0a67ea7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Given categorical data\n",
    "data = {'Cities': ['Paris', 'Rome', 'Lisbon', 'Madrid', 'Lisbon', 'Madrid', 'Lisbon', 'Paris', 'Lisbon']}\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Count of each city\n",
    "city_count = df['Cities'].value_counts()\n",
    "\n",
    "# Percentage of each city\n",
    "city_percentage = df['Cities'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Mode (most common city)\n",
    "city_mode = df['Cities'].mode()[0]\n",
    "\n",
    "print(\"Count of each city:\")\n",
    "print(city_count)\n",
    "print(\"\\nPercentage of each city:\")\n",
    "print(city_percentage)\n",
    "print(\"\\nMode (most common city):\", city_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d20c8a9-b406-4bb8-970d-08f4d6608f8f",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd9771b-505e-48ad-b2f5-d87f31db5d3e",
   "metadata": {},
   "source": [
    "- Bivariate Analysis involves the study of the relationship between two variables.\n",
    "- This analysis allows us to understand how the value of one variable changes with respect to the value of another variable\n",
    "- It includes various statistical techniques to explore the **association, correlation, or dependency** between pairs of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a1a72f-42db-4ccb-8f7c-17bf22b6afa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Synthetic data\n",
    "variavel1 = [17, 15, 18, 20, 22, 25, 30, 32, 35, 40, 55, 65]\n",
    "variavel2 = [30, 35, 40, 50, 45, 40, 55, 60, 65, 60, 90, 80]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Variavel1': variavel1, 'Variavel2': variavel2})\n",
    "\n",
    "# Association analysis\n",
    "association = df.groupby('Variavel1')['Variavel2'].mean()\n",
    "\n",
    "# Correlation analysis\n",
    "correlation = df.corr()\n",
    "\n",
    "# Dependency analysis\n",
    "dependency = np.cov(variavel1, variavel2)\n",
    "\n",
    "print(\"Association Analysis:\")\n",
    "print(association)\n",
    "print(\"\\nCorrelation Analysis:\")\n",
    "print(correlation)\n",
    "print(\"\\nDependency Analysis (Covariance Matrix):\")\n",
    "print(dependency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43406c4-3df2-4a58-98a5-73f79ea88d1e",
   "metadata": {},
   "source": [
    "### Linear correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e6d210-cb71-4a45-aa21-7a8f7e68b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Synthetic data\n",
    "variavel1 = [17, 15, 18, 20, 22, 25, 30, 32, 35, 40, 55, 65]\n",
    "variavel2 = [30, 35, 40, 50, 45, 40, 55, 60, 65, 60, 90, 80]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Variavel1': variavel1, 'Variavel2': variavel2})\n",
    "\n",
    "# Calculate the regression line\n",
    "model = LinearRegression().fit(np.array(variavel1).reshape(-1, 1), variavel2)\n",
    "slope = model.coef_[0]\n",
    "intercept = model.intercept_\n",
    "\n",
    "# Correlation analysis\n",
    "correlation = df.corr().iloc[0, 1]  # Pearson correlation coefficient\n",
    "n = len(df)  # Number of observations\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "# Calculate t-statistic and p-value for significance test\n",
    "t_statistic, p_value = scipy.stats.pearsonr(variavel1, variavel2)\n",
    "\n",
    "# Determine if the correlation is significant\n",
    "if p_value < alpha:\n",
    "    correlation_significance = \"Significant\"\n",
    "else:\n",
    "    correlation_significance = \"Not Significant\"\n",
    "\n",
    "# Scatter plot with regression line and correlation coefficient\n",
    "plt.scatter(variavel1, variavel2)\n",
    "plt.plot(variavel1, slope * np.array(variavel1) + intercept, color='red', label='Regression Line')  # Plot regression line\n",
    "plt.text(20, 70, f'Pearson Correlation: {correlation:.2f}\\nCorrelation Significance: {correlation_significance}', fontsize=10)\n",
    "plt.title('Scatter Plot of Variavel1 vs Variavel2 with Regression Line')\n",
    "plt.xlabel('Variavel1')\n",
    "plt.ylabel('Variavel2')\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8d471b-3cff-4081-a97a-87fd44481d3c",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842e080e-8046-450d-80e1-be74a9ba4592",
   "metadata": {},
   "source": [
    "- **Exercise 5.1** Calculate the mean, median, mode, variance, and standard deviation of the following dataset representing the ages of students in the Data Science course: [29, 26, 21, 20, 25, 22, 19, 21, 21, 26]. Suggestion: use statistical functions from the statistics library in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5581742-c076-408a-8867-c7752e061d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "# Dataset\n",
    "ages = [29, 26, 21, 20, 25, 22, 19, 21, 21, 26]\n",
    "\n",
    "# Mean\n",
    "mean_age = statistics.mean(ages)\n",
    "\n",
    "# Median\n",
    "median_age = statistics.median(ages)\n",
    "\n",
    "# Mode\n",
    "mode_age = statistics.mode(ages)\n",
    "\n",
    "# Variance\n",
    "variance_age = statistics.variance(ages)\n",
    "\n",
    "# Standard Deviation\n",
    "std_dev_age = statistics.stdev(ages)\n",
    "\n",
    "# Printing the results\n",
    "print(\"Mean:\", mean_age)\n",
    "print(\"Median:\", median_age)\n",
    "print(\"Mode:\", mode_age)\n",
    "print(\"Variance:\", variance_age)\n",
    "print(\"Standard Deviation:\", std_dev_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b511c0-aaa3-4fcd-b1bc-98af77d4221c",
   "metadata": {},
   "source": [
    "- **Exercise 5.2** Consider the following hypothetical data of two numerical variables: ùëã= [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] and ùëå= [2, 4, 5, 4, 5, 6, 5, 6, 5, 7].\n",
    "    - a) Calculate the correlation coefficient between ùëã and ùëå and test its statistical significance.\n",
    "    - b) Represent graphically the scatter of variables ùëã and ùëå."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f927b98-8c9a-4efb-8458-073477eb132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr, linregress\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "Y = np.array([2, 4, 5, 4, 5, 6, 5, 6, 5, 7])\n",
    "\n",
    "# Calculate correlation coefficient and p-value\n",
    "corr_coef, p_value = pearsonr(X, Y)\n",
    "\n",
    "# Perform linear regression\n",
    "slope, intercept, r_value, p_value_reg, std_err = linregress(X, Y)\n",
    "\n",
    "# Scatter plot\n",
    "plt.scatter(X, Y, label='Data')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Scatter plot of X and Y')\n",
    "\n",
    "# Add regression line\n",
    "plt.plot(X, intercept + slope*X, color='red', label='Regression Line')\n",
    "\n",
    "# Annotate correlation coefficient and p-value\n",
    "plt.text(0.5, 6, f'Correlation coefficient: {corr_coef:.2f}\\np-value: {p_value:.4f}', fontsize=10, bbox=dict(facecolor='lightgray', alpha=0.5))\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f56765-e2ff-45c1-995c-3d8c22148dc5",
   "metadata": {},
   "source": [
    "### Lesson #6 - Study Case: Supermarket Mall Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736810c6-7424-4ad0-b9e0-2abc0c2e1435",
   "metadata": {},
   "source": [
    "- File: 'https://stackabuse.s3.amazonaws.com/files/hierarchical-clustering-with-python-and-scikit-learn-shopping-data.csv' (exploratory analysis of supermarket mall customers' shopping profile)\n",
    "Challenges:\n",
    "    1. Import the data to the AWS platform for reading in Python and create a DataFrame (customer_data). Characterize the data in terms of structure and variable type.\n",
    "    2. Calculate summary statistics for numerical and categorical variables.\n",
    "    3. Check for missing observations. If any exist, remove them from the DataFrame.\n",
    "    4. Detect the presence of outliers using the boxplot method and remove them from the DataFrame. List the outliers and create a DataFrame without outliers.\n",
    "    5. Construct a scatter plot for the \"Annual Income\" and \"Spending Score\" variables, calculate their linear correlation, and test its statistical significance. Repeat the analysis only for females and only for individuals under 25 years old.\n",
    "    6. Construct a bar chart for the \"Spending Score\" by gender.\n",
    "    7. Convert the gender variable into a dummy variable (Male = 1, Female = 0) and into two dummy variables (Male = 1, Otherwise = 0; Female = 1, Otherwise = 0).\n",
    "    8. Proceed with the normalization and standardization of the \"Age\" and \"Annual Income\" variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68461a6-1e33-4904-9b5b-5f48a64e4781",
   "metadata": {},
   "source": [
    "**1. Import the data to the AWS platform for reading in Python and create a DataFrame (customer_data). Characterize the data in terms of structure and variable type.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27926282-31b1-49e9-b6a9-78d9f6a09666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import seaborn as sbn\n",
    "\n",
    "# Read Data\n",
    "customer_data = pd.read_csv('https://stackabuse.s3.amazonaws.com/files/hierarchical-clustering-with-python-and-scikit-learn-shopping-data.csv')\n",
    "customer_data\n",
    "\n",
    "# Print the column names and find the number of rows using index function\n",
    "print(customer_data.info())\n",
    "print(customer_data.columns)\n",
    "print(customer_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37da5f7e-53cf-4bc5-a2f9-ff4b46dcb8e8",
   "metadata": {},
   "source": [
    "**2. Calculate summary statistics for numerical and categorical variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a3b828-abd0-478d-9c26-7a0c02c3cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Estat√≠sticas sum√°rias das var. numericas:  {customer_data.describe()}\")\n",
    "print(\"Estat√≠sticas sum√°rias das idade:\", customer_data['Genre'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8263c895-a8c3-4f3c-adaf-0eabfa1ad544",
   "metadata": {},
   "source": [
    "**3. Check for missing observations. If any exist, remove them from the DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add1c63d-5ea4-4dcf-8148-4c8bdbddba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing data\n",
    "print(customer_data.isnull().any().any())\n",
    "print(customer_data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11017853-b43e-4e00-8d43-a043a485dc45",
   "metadata": {},
   "source": [
    "**4. Detect the presence of outliers using the boxplot method and remove them from the DataFrame. List the outliers and create a DataFrame without outliers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaacc560-fa78-42c1-885e-79ce658d6b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and remove outliers\n",
    "sbn.boxplot(customer_data['Age']) # No outliers\n",
    "sbn.boxplot(customer_data['Annual Income (k$)']) # There are outliers\n",
    "sbn.boxplot(customer_data['Spending Score (1-100)']) # No outliers\n",
    "\n",
    "# First quartil, third quartil and interquartil range  \n",
    "Q1 = customer_data['Annual Income (k$)'].quantile(0.25) \n",
    "Q3 = customer_data['Annual Income (k$)'].quantile(0.75) \n",
    "IQR = Q3 - Q1\n",
    "print(Q1, Q3, IQR)\n",
    "    \n",
    "# lower and upper values\n",
    "lower = Q1 - (1.5 * IQR)\n",
    "upper = Q3 + (1.5 * IQR)\n",
    "print(lower, upper)\n",
    "\n",
    "# To print all the data above the upper value and below the lower value \n",
    "outliers = customer_data[((customer_data['Annual Income (k$)'] < lower) | \n",
    "                          (customer_data['Annual Income (k$)'] > upper))]\n",
    "print(outliers)\n",
    "\n",
    "# To print the data without outliers\n",
    "clean_data = customer_data[~((customer_data['Annual Income (k$)'] < lower) |\n",
    "                             (customer_data['Annual Income (k$)'] > upper))]\n",
    "print(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68860164-3bf5-45cf-9f9c-8f0959f97a25",
   "metadata": {},
   "source": [
    "**5. Construct a scatter plot for the \"Annual Income\" and \"Spending Score\" variables, calculate their linear correlation, and test its statistical significance. Repeat the analysis only for females and only for individuals under 25 years old.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9eb123-d7bd-4f0e-8d64-e0a5bbb4d55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "sns.lmplot(x='Annual Income (k$)', y='Spending Score (1-100)', data=clean_data)\n",
    "plt.title('Dispers√£o do Rendimento vs Gastos')\n",
    "plt.xlabel('Annual Income (k$)')\n",
    "plt.ylabel('Spending Score (1-100)')\n",
    "plt.show()\n",
    "\n",
    "correlation_coefficient, p_value = pearsonr(clean_data['Spending Score (1-100)'], clean_data['Annual Income (k$)'])\n",
    "print(\"Coeficiente de correla√ß√£o de Pearson:\", correlation_coefficient)\n",
    "print(\"Valor-p:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e192ec1-cc2a-4050-b08e-574c260c26e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_data = clean_data[clean_data['Genre'] == 'Female']\n",
    "sns.lmplot(x='Annual Income (k$)', y='Spending Score (1-100)', data=female_data)\n",
    "plt.title('Dispers√£o do Rendimento vs Gastos nas mulheres')\n",
    "plt.xlabel('Annual Income (k$)')\n",
    "plt.ylabel('Spending Score (1-100)')\n",
    "plt.show() \n",
    "correlation_coefficient_female, p_value = pearsonr(female_data['Spending Score (1-100)'], female_data['Annual Income (k$)'])\n",
    "print(\"Coeficiente de correla√ß√£o de Pearson (female):\", correlation_coefficient_female)\n",
    "print(\"Valor-p (female):\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855fc8cc-b391-465b-a8d9-2485c6a89941",
   "metadata": {},
   "outputs": [],
   "source": [
    "young_data = clean_data[clean_data['Age'] < 25]\n",
    "sns.lmplot(x='Annual Income (k$)', y='Spending Score (1-100)', data=young_data)\n",
    "plt.title('Dispers√£o do Rendimento vs Gastos nos jovens com < 25 anos')\n",
    "plt.xlabel('Annual Income (k$)')\n",
    "plt.ylabel('Spending Score (1-100)')\n",
    "plt.show() \n",
    "correlation_coefficient_young, p_value = pearsonr(young_data['Spending Score (1-100)'], young_data['Annual Income (k$)'])\n",
    "print(\"Coeficiente de correla√ß√£o de Pearson (young):\", correlation_coefficient_young)\n",
    "print(\"Valor-p (young):\", p_value) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05916dcf-1e38-488d-b0c9-6426f86acc82",
   "metadata": {},
   "source": [
    "**6. Construct a bar chart for the \"Spending Score\" by gender.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30d51355-46ce-4023-917e-200d3fa121b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Genre', y='Spending Score (1-100)', data=clean_data, errorbar=None)\n",
    "plt.title('Gastos')\n",
    "plt.xlabel('Sexo')\n",
    "plt.ylabel('Spending Score (1-100)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a85eb7-14cd-4b13-bd89-0c5b1d41aed4",
   "metadata": {},
   "source": [
    "**7. Convert the gender variable into a dummy variable (Male = 1, Female = 0) and into two dummy variables (Male = 1, Otherwise = 0; Female = 1, Otherwise = 0).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d485846-c746-4452-aecc-55275eb2b04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1) Create only one dummy\n",
    "gender_dummy1 = pd.get_dummies(clean_data['Genre'], drop_first=True )\n",
    "print(gender_dummy1)\n",
    "clean_data1 = pd.concat([clean_data,gender_dummy1],axis=1)\n",
    "print(clean_data1)\n",
    "\n",
    "# Option 2) Create two dummmies \n",
    "gender_dummy2 = pd.get_dummies(clean_data['Genre'])\n",
    "print(gender_dummy2)\n",
    "clean_data2 = pd.concat([clean_data,gender_dummy2],axis=1)\n",
    "print(clean_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142555a6-718b-4626-b18a-cb3605fea0d6",
   "metadata": {},
   "source": [
    "**8. Proceed with the normalization and standardization of the \"Age\" and \"Annual Income\" variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcb6d79-b68a-43cc-be67-50c69e06c83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = clean_data.iloc[:, 3:5].values\n",
    "print(data)\n",
    "\n",
    "# option 1: StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler1 = StandardScaler() \n",
    "scaled_data1 = scaler1.fit_transform(data) \n",
    "print(scaled_data1)\n",
    "\n",
    "# option 2: MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler   \n",
    "scaler2 = MinMaxScaler()\n",
    "scaled_data2 = scaler2.fit_transform(data)\n",
    "print(scaled_data2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
